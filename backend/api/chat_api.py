"""
IntelliSearch èŠå¤©APIæœåŠ¡ - æ”¯æŒçœŸæ­£çš„æµå¼è¾“å‡º
åŸºäºLLMClientå®ç°çœŸå®çš„æµå¼å“åº”
"""
import os
import sys
import json
import logging
import uuid
from datetime import datetime
from typing import Dict, Any, Optional, AsyncGenerator

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.getcwd())
from config.config_loader import Config

# Load environment variables from config.yaml
config = Config.get_instance()

from backend.core.llm_client import LLMClient
from core.logger import get_logger

# é…ç½®æ—¥å¿—
logging.getLogger("mcp").setLevel(logging.CRITICAL)
logger = get_logger(__name__)

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/api/chat", tags=["chat"])

# è¯·æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None
    use_tools: bool = True
    model_name: Optional[str] = "deepseek-chat"
    max_tool_calls: Optional[int] = 5
    system_prompt: Optional[str] = None

# å­˜å‚¨ä¼šè¯
sessions: Dict[str, LLMClient] = {}

# åŠ è½½é»˜è®¤ç³»ç»Ÿæç¤ºè¯
def load_system_prompt():
    """åŠ è½½ç³»ç»Ÿæç¤ºè¯"""
    try:
        with open("prompts/base_system_prompt.md", "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return "You are a helpful assistant with access to various tools."


def get_or_create_session(session_id: Optional[str] = None, **kwargs) -> str:
    """è·å–æˆ–åˆ›å»ºä¼šè¯"""
    if session_id and session_id in sessions:
        return session_id

    # åˆ›å»ºæ–°ä¼šè¯ID
    new_session_id = session_id or str(uuid.uuid4())

    # åˆ›å»ºæ–°çš„LLMå®¢æˆ·ç«¯
    system_prompt = kwargs.get('system_prompt') or load_system_prompt()
    model_name = kwargs.get('model_name', 'deepseek-chat')
    max_tool_calls = kwargs.get('max_tool_calls', 20)

    try:
        # è·å–base_urlå’Œapi_keyé…ç½®
        base_url = os.environ.get("BASE_URL", "https://api.deepseek.com")
        api_key_env = "OPENAI_API_KEY"

        chat_client = LLMClient(
            model_name=model_name,
            base_url=base_url,
            api_key_env=api_key_env
        )

        # è®¾ç½®ç³»ç»Ÿæç¤ºè¯å’Œæœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
        chat_client.system_prompt = system_prompt
        chat_client.max_tool_calls = max_tool_calls

        sessions[new_session_id] = chat_client
        logger.info(f"Created new session: {new_session_id}")
    except Exception as e:
        logger.error(f"Failed to create session {new_session_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to create session: {str(e)}")

    return new_session_id


def format_sse_event(event_type: str, data: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–SSEäº‹ä»¶"""
    event_data = {
        "type": event_type,
        "timestamp": datetime.now().isoformat(),
        **data
    }
    return f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"


async def stream_chat_process(chat_client: LLMClient, user_message: str) -> AsyncGenerator[str, None]:
    """
    çœŸæ­£çš„æµå¼èŠå¤©å¤„ç† - åŸºäºLLMClientçš„æµå¼å®ç°
    """
    try:
        # å‘é€å¼€å§‹äº‹ä»¶
        yield format_sse_event("start", {"message": "å¼€å§‹å¤„ç†æ‚¨çš„è¯·æ±‚..."})

        # åˆ—å‡ºå¯ç”¨å·¥å…·
        yield format_sse_event("tools_discovery", {"message": "ğŸ”Œ æ­£åœ¨è¿æ¥å’Œå‘ç°å·¥å…·..."})

        tools = await chat_client.mcp_client.list_tools()
        if not tools:
            yield format_sse_event("warning", {"message": "æœªå‘ç°å¯ç”¨å·¥å…·"})

        chat_client.logger.info(f"Available Tools: {tools}")

        yield format_sse_event("tools_ready", {
            "message": f"âœ… å‘ç° {len(tools)} ä¸ªå¯ç”¨å·¥å…·",
            "tools_count": len(tools)
        })

        # å‡†å¤‡æ¶ˆæ¯å†å²ï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æ¶ˆæ¯
        messages = [
            {"role": "system", "content": chat_client.system_prompt},
            {"role": "user", "content": user_message}
        ]

        # å¤„ç†æŸ¥è¯¢ - ä½¿ç”¨çœŸæ­£çš„æµå¼å“åº”
        tool_call_count = 0
        max_tool_calls = getattr(chat_client, 'max_tool_calls', 20)

        async for event in chat_client.chat_completion_stream(messages, tools, max_tool_calls):
            event_type = event["type"]

            if event_type == "content":
                # çœŸæ­£çš„æµå¼å†…å®¹è¾“å‡º
                yield format_sse_event("content", {
                    "content": event["content"]
                })

            elif event_type == "tool_call_start":
                tool_call_count += 1
                tool_call = event["tool_call"]
                yield format_sse_event("tool_call_start", {
                    "message": f"ğŸ› ï¸ è°ƒç”¨å·¥å…·: {tool_call['name']}",
                    "tool_call": tool_call,
                    "tool_index": tool_call_count,
                    "round": 1  # LLMClientå†…éƒ¨å¤„ç†è½®æ¬¡
                })

            elif event_type == "tool_call_delta":
                tool_call = event["tool_call"]
                yield format_sse_event("tool_call_delta", {
                    "tool_call": tool_call
                })

            elif event_type == "tool_result":
                tool_result = event["tool_result"]
                # å¤„ç†å·¥å…·ç»“æœæˆªæ–­
                result_content = tool_result["result"]
                if len(result_content) > 500:
                    truncated_result = result_content[:500] + "...(å·²æˆªæ–­)"
                    yield format_sse_event("tool_result", {
                        "message": "âœ… å·¥å…·æ‰§è¡Œç»“æœ (å·²æˆªæ–­):",
                        "tool_name": tool_result["name"],
                        "result": truncated_result,
                        "full_length": len(result_content),
                        "truncated": True
                    })
                else:
                    yield format_sse_event("tool_result", {
                        "message": "âœ… å·¥å…·æ‰§è¡Œç»“æœ:",
                        "tool_name": tool_result["name"],
                        "result": result_content,
                        "full_length": len(result_content),
                        "truncated": False
                    })

            elif event_type == "error":
                yield format_sse_event("error", {
                    "message": f"âŒ å¤„ç†é”™è¯¯: {event['error']}"
                })

        yield format_sse_event("session_complete", {
            "message": "ğŸ‰ å¯¹è¯å®Œæˆ"
        })

    except Exception as e:
        logger.error(f"Error in stream_chat_process: {e}", exc_info=True)
        yield format_sse_event("error", {
            "message": f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
            "error": str(e)
        })

    finally:
        # ç¡®ä¿æ¸…ç†MCPè¿æ¥
        try:
            await chat_client.mcp_client.server_manager.close_all_connections()
        except Exception as e:
            logger.error(f"Error closing MCP connections: {e}")


@router.post("")
@router.post("/")
async def chat(request: ChatRequest):
    """éæµå¼èŠå¤©æ¥å£"""

    try:
        # è·å–æˆ–åˆ›å»ºä¼šè¯
        session_id = get_or_create_session(
            session_id=request.session_id,
            model_name=request.model_name,
            max_tool_calls=request.max_tool_calls,
            system_prompt=request.system_prompt
        )

        # ç®€å•çš„å¯¹è¯å“åº”ï¼ˆä¸æµå¼ï¼‰
        response = ""
        if not request.use_tools:
            response = "ä½ å¥½ï¼æˆ‘æ˜¯IntelliSearchæ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œå„ç§æœç´¢å’Œä¿¡æ¯æŸ¥è¯¢ã€‚å¦‚éœ€ä½¿ç”¨æœç´¢åŠŸèƒ½ï¼Œè¯·åœ¨è¯·æ±‚ä¸­è®¾ç½® use_tools=trueã€‚"
        else:
            response = "æ‚¨å¥½ï¼æˆ‘æ˜¯IntelliSearchæ™ºèƒ½åŠ©æ‰‹ï¼Œé…å¤‡äº†å¼ºå¤§çš„æœç´¢å·¥å…·ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³æœç´¢ä»€ä¹ˆä¿¡æ¯ï¼Ÿ"

        return {"content": response, "session_id": session_id}

    except Exception as e:
        logger.error(f"Error in chat: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@router.post("/stream")
async def chat_stream(request: ChatRequest):
    """å¢å¼ºçš„æµå¼èŠå¤©æ¥å£"""

    try:
        # è·å–æˆ–åˆ›å»ºä¼šè¯
        session_id = get_or_create_session(
            session_id=request.session_id,
            model_name=request.model_name,
            max_tool_calls=request.max_tool_calls,
            system_prompt=request.system_prompt
        )

        chat_client = sessions[session_id]

        async def generate():
            """ç”ŸæˆSSEæµå¼å“åº”"""
            try:
                async for event in stream_chat_process(chat_client, request.message):
                    yield event

                # å‘é€ç»“æŸæ ‡è®°
                yield format_sse_event("done", {"message": "ä¼šè¯ç»“æŸ"})
                yield "data: [DONE]\n\n"

            except Exception as e:
                logger.error(f"Error in generate: {e}")
                yield format_sse_event("error", {"message": f"ç”Ÿæˆå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"})
                yield "data: [DONE]\n\n"

        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
            }
        )

    except Exception as e:
        logger.error(f"Error in chat_stream: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@router.delete("/sessions/{session_id}")
async def delete_session(session_id: str):
    """åˆ é™¤ä¼šè¯"""
    if session_id not in sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    try:
        # æ¸…ç†MCPè¿æ¥
        await sessions[session_id].mcp_client.server_manager.close_all_connections()
        del sessions[session_id]
        return {"message": "Session deleted successfully"}
    except Exception as e:
        logger.error(f"Error deleting session {session_id}: {e}")
        del sessions[session_id]  # å³ä½¿å‡ºé”™ä¹Ÿè¦åˆ é™¤ä¼šè¯
        return {"message": "Session deleted (with cleanup errors)"}


@router.get("/sessions")
async def list_sessions():
    """åˆ—å‡ºæ‰€æœ‰æ´»è·ƒä¼šè¯"""
    session_info = []
    for session_id, chat_client in sessions.items():
        session_info.append({
            "session_id": session_id,
            "model_name": chat_client.model_name,
            "max_tool_calls": getattr(chat_client, 'max_tool_calls', 5)
        })

    return {"sessions": session_info, "total": len(session_info)}


@router.get("/tools")
async def list_available_tools():
    """åˆ—å‡ºå¯ç”¨å·¥å…·ï¼ˆä½¿ç”¨ä¸´æ—¶ä¼šè¯ï¼‰"""
    try:
        # åˆ›å»ºä¸´æ—¶ä¼šè¯æ¥è·å–å·¥å…·åˆ—è¡¨
        base_url = os.environ.get("BASE_URL", "https://api.deepseek.com")
        api_key_env = "OPENAI_API_KEY"

        temp_client = LLMClient(
            model_name="deepseek-chat",
            base_url=base_url,
            api_key_env=api_key_env
        )
        tools = await temp_client.mcp_client.list_tools()
        await temp_client.mcp_client.server_manager.close_all_connections()

        return {"tools": tools, "total": len(tools)}
    except Exception as e:
        logger.error(f"Error listing tools: {e}")
        raise HTTPException(status_code=500, detail=f"Error listing tools: {str(e)}")